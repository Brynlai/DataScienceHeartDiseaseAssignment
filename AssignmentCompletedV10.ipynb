{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brynlai/DataScienceHeartDiseaseAssignment/blob/Bryan/AssignmentCompletedV10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B. Data Understanding\n",
        "1. Data Collection\n",
        "2. Data Description\n",
        "3. Data Exploration"
      ],
      "metadata": {
        "id": "GMwkE05qR-ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.1. Data Collection"
      ],
      "metadata": {
        "id": "9wvkuMLzTO2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# B. Data Understanding - 1. Data Collection\n",
        "# @title\n",
        "!pip install ucimlrepo\n",
        "!pip install pandas matplotlib seaborn scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Fetch Heart Disease dataset from UCI ML Repository\n",
        "heart_disease_bunch = fetch_ucirepo(id=45)\n",
        "\n",
        "# Load into DataFrame\n",
        "heart_disease = pd.DataFrame(data=heart_disease_bunch.data.features,\n",
        "                             columns=heart_disease_bunch.data.feature_names,\n",
        "                             index=heart_disease_bunch.data.ids)\n",
        "heart_disease = pd.concat([heart_disease, heart_disease_bunch.data.targets], axis=1)"
      ],
      "metadata": {
        "id": "rQJYLjk7o-mg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.2. Data Description"
      ],
      "metadata": {
        "id": "EKwa1c9YPu67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# B. Data Understanding: - 2. Data Description\n",
        "def print_col(col):\n",
        "  # Get fequency of each result in groups\n",
        "  group_sizes = df.groupby(col).size()\n",
        "  print(f\"Column: {'col'}\")\n",
        "  print(group_sizes)\n",
        "  print()\n",
        "\n",
        "def print_group_sizes(df):\n",
        "    for column in df.columns:\n",
        "        # Get fequency of each result in groups\n",
        "        print_col(column)"
      ],
      "metadata": {
        "id": "gC6_zKXU8MPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy hear_disease to df.\n",
        "df = heart_disease\n",
        "\n",
        "# Show column names, null value count and data type\n",
        "print(df.info())\n",
        "\n",
        "# Rename num to target.\n",
        "df = df.rename(columns={'num': 'target'})\n",
        "\n",
        "\n",
        "# Rename Columns to make them more readable\n",
        "column_names = {\n",
        "    \"age\": \"Age\",\n",
        "    \"sex\": \"Gender\",\n",
        "    \"cp\": \"ChestPainType\",\n",
        "    \"trestbps\": \"RestingBP\",\n",
        "    \"fbs\": \"FastBloodSugar\",\n",
        "    \"restecg\": \"RestingECG\",\n",
        "    \"exang\": \"ExerciseAngina\",\n",
        "    \"slope\": \"ExerciseSlope\",\n",
        "    \"ca\": \"MajorVessels\",\n",
        "    \"thal\": \"ThalliumStress\",\n",
        "    \"target\": \"HeartDisease\",\n",
        "    \"chol\": \"SerumCholesterol\",\n",
        "    \"thalach\": \"MaxHeartRate\",\n",
        "    \"oldpeak\": \"OldPeak\"\n",
        "}\n",
        "df.rename(columns=column_names, inplace=True)\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "id": "DzHjMHGZ7tMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.3 Data Exploration"
      ],
      "metadata": {
        "id": "mt0Em00z9sOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data types and null\n",
        "print(df.info())\n",
        "\n",
        "# Summary Statistics\n",
        "summary_stats = df.describe()\n",
        "print(summary_stats)"
      ],
      "metadata": {
        "id": "QgcbqwYXCEAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution Plots of the columns values\n",
        "for column in df.columns:\n",
        "    sns.histplot(df[column], kde=True, bins=20)\n",
        "    plt.title(f'Distribution of {column}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KCEjpFJFBtaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pair plot with customization\n",
        "sns.pairplot(df, vars=df.columns, diag_kind='kde', markers='o')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8cDrD6yT9vlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "ax = sns.heatmap(corr_matrix,\n",
        "                 annot=True,\n",
        "                 linewidths=0.5,\n",
        "                 fmt=\".2f\",\n",
        "                 cmap=\"YlGnBu\");\n",
        "bottom, top = ax.get_ylim()\n",
        "ax.set_ylim()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "92EyU01rPwHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C. Data Preperation\n",
        "1. Data Cleaning\n",
        "2. Data transformation"
      ],
      "metadata": {
        "id": "xQKayQXHTFQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C.1. Data Cleaning"
      ],
      "metadata": {
        "id": "4yz1Rg_QT51F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C. Data Preperation - 1. Data Cleaning\n",
        "# Check for any duplicate observation\n",
        "duplicate_rows = df.duplicated()\n",
        "print(\"Number of duplicate rows before:\", duplicate_rows.sum())\n",
        "\n",
        "# Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Check for duplicate rows again\n",
        "duplicate_rows = df.duplicated()\n",
        "print(\"Number of duplicate rows after:\", duplicate_rows.sum())"
      ],
      "metadata": {
        "id": "AtzvYm_rSZOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C. Data Preperation - 1. Data Cleaning\n",
        "# Check for missing values in each column\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values in each column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Replace missing values with median of each column, only if the column is numerical\n",
        "for column in df.columns:\n",
        "    if df[column].dtype in [np.int64, np.float64]:  # Check if the column is numerical\n",
        "        df[column] = df[column].fillna(df[column].median())\n",
        "\n",
        "# Check if there are any missing values left\n",
        "missing_values_after = df.isnull().sum()\n",
        "print(\"Missing values after replacing with medians:\")\n",
        "print(missing_values_after)"
      ],
      "metadata": {
        "id": "rTxsFBhESeN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C. Data Preperation - 1. Data Cleaning\n",
        "def remove_outliers(df, columns, threshold=3):\n",
        "    outliers = {}\n",
        "    for column in columns:\n",
        "        mean = df[column].mean()\n",
        "        std = df[column].std()\n",
        "        z_scores = np.abs((df[column] - mean) / std)\n",
        "        outlier_indices = z_scores >= threshold\n",
        "        outliers[column] = df[column][outlier_indices].tolist()\n",
        "        df = df[~outlier_indices]\n",
        "    return df, outliers\n",
        "\n",
        "# Specify columns to check for outliers\n",
        "columns_to_check = ['RestingBP', 'SerumCholesterol', 'MaxHeartRate', 'OldPeak']\n",
        "\n",
        "# Remove outliers from the DataFrame and print the outliers\n",
        "df_cleaned, outliers = remove_outliers(df, columns_to_check)\n",
        "\n",
        "# Print the outliers for each column\n",
        "print(\"Outliers List\\n\")\n",
        "for column, outlier_list in outliers.items():\n",
        "    print(f\"Outliers in {column}: {outlier_list}\")\n",
        "print()\n",
        "\n",
        "\n",
        "# Create distribution plots before and after removing outliers\n",
        "fig, axes = plt.subplots(nrows=len(columns_to_check), ncols=2, figsize=(12, 6*len(columns_to_check)))\n",
        "for i, column in enumerate(columns_to_check):\n",
        "    sns.histplot(df[column], ax=axes[i, 0], kde=True, bins=20)\n",
        "    axes[i, 0].set_title(f'Distribution of {column} Before Removing Outliers')\n",
        "    sns.histplot(df_cleaned[column], ax=axes[i, 1], kde=True, bins=20)\n",
        "    axes[i, 1].set_title(f'Distribution of {column} After Removing Outliers')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MMqU1E4tSjMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C.2. Data Transformation"
      ],
      "metadata": {
        "id": "49siaE_LUAdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before\n",
        "print_col('HeartDisease')\n",
        "\n",
        "# Change anything above 0 into 1\n",
        "df['HeartDisease'] = df['HeartDisease'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# After\n",
        "print_col('HeartDisease')"
      ],
      "metadata": {
        "id": "iQ3DxT5G_VeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C. Data Preperation - 1. Data Transformation\n",
        "columns_to_binned = ['Age', 'RestingBP', 'SerumCholesterol', 'MaxHeartRate', 'OldPeak']\n",
        "\n",
        "# # Before:\n",
        "# print(\"\\n\\nBefore Binning: -----------\")\n",
        "# for column in columns_to_binned:\n",
        "#     print_col(column)\n",
        "\n",
        "# Visualize before binning\n",
        "fig, axes = plt.subplots(nrows=len(columns_to_binned), ncols=1, figsize=(8, 6*len(columns_to_binned)))\n",
        "for i, column in enumerate(columns_to_binned):\n",
        "    sns.histplot(df[column], ax=axes[i], kde=True, bins=20)\n",
        "    axes[i].set_title(f'Distribution of {column} Before Binning')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Bins for age\n",
        "age_bins = [10, 20, 30, 40, 50, 60, np.inf]\n",
        "age_labels = [1, 2, 3, 4, 5, 6]  # Assign numerical labels\n",
        "df['Age_binned'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, include_lowest=True)\n",
        "\n",
        "# Bins for resting blood pressure\n",
        "trestbps_bins = [0, 100, 120, 140, 160, np.inf]\n",
        "trestbps_labels = [1, 2, 3, 4, 5]  # Assign numerical labels\n",
        "df['RestingBP_binned'] = pd.cut(df['RestingBP'], bins=trestbps_bins, labels=trestbps_labels, include_lowest=True)\n",
        "\n",
        "# Bins for serum cholesterol\n",
        "chol_bins = [0, 160, 200, 240, 280, np.inf]\n",
        "chol_labels = [1, 2, 3, 4, 5]  # Assign numerical labels\n",
        "df['SerumCholesterol_binned'] = pd.cut(df['SerumCholesterol'], bins=chol_bins, labels=chol_labels, include_lowest=True)\n",
        "\n",
        "# Bins for maximum heart rate achieved\n",
        "thalach_bins = [0, 90, 120, 150, 180, np.inf]\n",
        "thalach_labels = [1, 2, 3, 4, 5]  # Assign numerical labels\n",
        "df['MaxHeartRate_binned'] = pd.cut(df['MaxHeartRate'], bins=thalach_bins, labels=thalach_labels, include_lowest=True)\n",
        "\n",
        "# Bins for ST depression induced by exercise\n",
        "oldpeak_bins = [0, 0.5, 1.5, 2.5, 3.5, np.inf]\n",
        "oldpeak_labels = [1, 2, 3, 4, 5]  # Assign numerical labels\n",
        "df['OldPeak_binned'] = pd.cut(df['OldPeak'], bins=oldpeak_bins, labels=oldpeak_labels, include_lowest=True)\n",
        "\n",
        "# Drop original numerical columns\n",
        "df = df.drop(['Age', 'RestingBP', 'SerumCholesterol', 'MaxHeartRate', 'OldPeak'], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "columns_binned = ['Age_binned', 'RestingBP_binned', 'SerumCholesterol_binned', 'MaxHeartRate_binned', 'OldPeak_binned']\n",
        "# After:\n",
        "# print(\"\\n\\nAfter Binning: -----------\")\n",
        "# for column in columns_binned:\n",
        "#     print_col(column)\n",
        "\n",
        "# Visualize after binning\n",
        "fig, axes = plt.subplots(nrows=len(columns_binned), ncols=1, figsize=(8, 6*len(columns_binned)))\n",
        "for i, column in enumerate(columns_binned):\n",
        "    sns.histplot(df[column], ax=axes[i], kde=False, bins=None)\n",
        "    axes[i].set_title(f'Distribution of {column} After Binning')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lmpOp7ws7H0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "ax = sns.heatmap(corr_matrix,\n",
        "                 annot=True,\n",
        "                 linewidths=0.5,\n",
        "                 fmt=\".2f\",\n",
        "                 cmap=\"YlGnBu\");\n",
        "bottom, top = ax.get_ylim()\n",
        "ax.set_ylim()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fk5GPMa93feu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In the correlation matrix, these attributes were +/- 0.25.\n",
        "correlated_features = ['HeartDisease','Gender', 'ChestPainType', 'ExerciseAngina', 'ExerciseSlope',\n",
        "                     'MajorVessels', 'ThalliumStress', 'MaxHeartRate_binned', 'OldPeak_binned']\n",
        "\n",
        "# Clean and Simple Histograms\n",
        "for column in correlated_features:\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.histplot(df[column], ax=ax, kde=True, bins=20)\n",
        "    ax.set_title(f'Distribution of {column}')\n",
        "    ax.set_xlabel(column)\n",
        "    ax.set_ylabel('Frequency')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FLOUsazzJjbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D. Modelling\n",
        "1. Scale\n",
        "2. Set seed for reproducibility\n",
        "3. Split data\n",
        "4. Train Data\n",
        "5. Print Results"
      ],
      "metadata": {
        "id": "jJseLVYdUnT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the relevant features\n",
        "# In the correlation matrix, these attributes were +/- 0.25.\n",
        "relevant_features = ['Gender', 'ChestPainType', 'ExerciseAngina', 'ExerciseSlope',\n",
        "                     'MajorVessels', 'ThalliumStress', 'MaxHeartRate_binned', 'OldPeak_binned']\n",
        "X = df[relevant_features]\n",
        "# If you want them all:\n",
        "# X = df.drop('HeartDisease' , axis=1)\n",
        "y = df['HeartDisease']\n",
        "\n",
        "# Scaling the data improves stability, consistency and performance.\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Same random number generated every time: Reproducibility\n",
        "np.random.seed(564)\n",
        "test_sizes = {}\n",
        "\n",
        "#for i in range(5, 51, 5):\n",
        "# Commonly 80/20, 70/30, 50/50.\n",
        "# for i in [20, 30, 50]:\n",
        "for i in [20, 30, 50]:\n",
        "    test_sizes[f\"{i}%\"] = i / 100\n",
        "\n",
        "count = 0\n",
        "best_models = {}\n",
        "for sizeOfT, testSize in test_sizes.items():\n",
        "    print(f\"\\n--------  Iteration {count} Test size: {sizeOfT}: --------\")\n",
        "    count += 1\n",
        "\n",
        "    # Split data using the fixed random state\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=200) # Same split of data everytime\n",
        "\n",
        "    # All models used\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(),\n",
        "        \"SVM\": SVC()\n",
        "    }\n",
        "\n",
        "    modelPerformance = {}\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=200)\n",
        "\n",
        "    # Fit the models\n",
        "    for model_name, model in models.items():\n",
        "        # Normal method: Train and evaluate the model on the test set\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        test_accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"{model_name} - Test Accuracy: {test_accuracy:.3f}\")\n",
        "\n",
        "        # StratifiedKFold for cross-validation\n",
        "        cv_scores = cross_val_score(model, X, y, cv=skf)\n",
        "        avg_cv_score = cv_scores.mean()\n",
        "        print(f\"{model_name} - Cross-Validation Accuracy: {avg_cv_score:.3f}\")\n",
        "        modelPerformance[model_name] = (avg_cv_score, test_accuracy)\n",
        "        print()\n",
        "\n",
        "\n",
        "    # Find and print the best model for this test size based on cross-validation score\n",
        "    best_model_name = max(modelPerformance, key=lambda x: modelPerformance[x])\n",
        "    best_model_cv_accuracy, best_model_test_accuracy = modelPerformance[best_model_name]\n",
        "    print(f\"Best Model: {best_model_name} - Cross-Validation Accuracy: {best_model_cv_accuracy:.3f} , Test Accuracy: {best_model_test_accuracy:.3f}\")\n",
        "\n",
        "    # Store the best model for each test size\n",
        "    best_models[sizeOfT] = (best_model_name, best_model_cv_accuracy, best_model_test_accuracy)"
      ],
      "metadata": {
        "id": "qqcfCanNkdzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display best models for each test size\n",
        "print(\"\\nBest Models for Each Test Size:\")\n",
        "for test_size, (best_model, cv_accuracy, test_accuracy) in best_models.items():\n",
        "    print(f\"Test Size: {test_size}\\n  Best Model: {best_model}\\n  CV Accuracy: {cv_accuracy:.3f}\\n  Test Accuracy: {test_accuracy:.3f}\\n\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "test_sizes = list(best_models.keys())\n",
        "models = [\"Logistic Regression\", \"Decision Tree\", \"SVM\"]\n",
        "\n",
        "for test_size in test_sizes:\n",
        "    cv_accuracies = [modelPerformance[model][0] for model in models]\n",
        "    test_accuracies = [modelPerformance[model][1] for model in models]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    x = np.arange(len(models))\n",
        "    bar_width = 0.35\n",
        "\n",
        "    # Plot cross-validation and test accuracy bars\n",
        "    ax.bar(x - bar_width/2, cv_accuracies, bar_width, label='CV Accuracy')\n",
        "    ax.bar(x + bar_width/2, test_accuracies, bar_width, label='Test Accuracy')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(models)\n",
        "    ax.set_xlabel('Model')\n",
        "    ax.set_ylabel('Accuracy')\n",
        "    ax.set_title(f'Model Performance at {test_size}')\n",
        "    ax.legend(loc='lower left')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "1UrHiUWSAiwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_group_sizes(df)"
      ],
      "metadata": {
        "id": "pTk1wRPs6Ayd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the entire training set\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# Function to get user input and predict\n",
        "def get_user_input_and_predict():\n",
        "    print(\"Enter the following values:\")\n",
        "\n",
        "    # Gender (male/female)\n",
        "    # - male: 1 (206 occurrences)\n",
        "    # - female: 0 (97 occurrences)\n",
        "    while True:\n",
        "        try:\n",
        "            gender = int(input(\"Gender (1 for male, 0 for female): \\n\"\n",
        "                               \"  1: Male (206 occurrences)\\n\"\n",
        "                               \"  0: Female (97 occurrences)\\n\"\n",
        "                               \"Enter your gender: \"))\n",
        "            if gender in [0, 1]:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter 0 for female or 1 for male.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a numeric value.\")\n",
        "\n",
        "    # Chest Pain Type (typical/atypical/non-anginal/asymptomatic)\n",
        "    # - typical: 1 (23 occurrences)\n",
        "    # - atypical: 2 (50 occurrences)\n",
        "    # - non-anginal: 3 (86 occurrences)\n",
        "    # - asymptomatic: 4 (144 occurrences)\n",
        "    while True:\n",
        "        try:\n",
        "            chest_pain_type = int(input(\"Chest Pain Type (1-4): \\n\"\n",
        "                                        \"  1: Typical angina (23 occurrences)\\n\"\n",
        "                                        \"  2: Atypical angina (50 occurrences)\\n\"\n",
        "                                        \"  3: Non-anginal pain (86 occurrences)\\n\"\n",
        "                                        \"  4: Asymptomatic (144 occurrences)\\n\"\n",
        "                                        \"Enter your chest pain type: \"))\n",
        "            if 1 <= chest_pain_type <= 4:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter a value between 1 and 4.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a numeric value.\")\n",
        "\n",
        "    # Exercise Angina (yes/no)\n",
        "    # - yes: 1 (99 occurrences)\n",
        "    # - no: 0 (204 occurrences)\n",
        "    while True:\n",
        "        try:\n",
        "            exercise_angina = int(input(\"Exercise Angina (1 for yes, 0 for no): \\n\"\n",
        "                                        \"  1: Yes (99 occurrences)\\n\"\n",
        "                                        \"  0: No (204 occurrences)\\n\"\n",
        "                                        \"Enter your exercise angina status: \"))\n",
        "            if exercise_angina in [0, 1]:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter 0 for no or 1 for yes.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a numeric value.\")\n",
        "\n",
        "    # Exercise Slope (up/flat/down)\n",
        "    # - up: 1 (142 occurrences)\n",
        "    # - flat: 2 (140 occurrences)\n",
        "    # - down: 3 (21 occurrences)\n",
        "    while True:\n",
        "        try:\n",
        "            exercise_slope = int(input(\"Exercise Slope (1-3): \\n\"\n",
        "                                       \"  1: Up (142 occurrences)\\n\"\n",
        "                                       \"  2: Flat (140 occurrences)\\n\"\n",
        "                                       \"  3: Down (21 occurrences)\\n\"\n",
        "                                       \"Enter your exercise slope: \"))\n",
        "            if 1 <= exercise_slope <= 3:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter a value between 1 and 3.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a numeric value.\")\n",
        "\n",
        "    # Major Vessels (0-3)\n",
        "    # - 0: 180 occurrences\n",
        "    # - 1: 65 occurrences\n",
        "    # - 2: 38 occurrences\n",
        "    # - 3: 20 occurrences\n",
        "    while True:\n",
        "        try:\n",
        "            major_vessels = int(input(\"Major Vessels (0-3): \\n\"\n",
        "                                      \"  0: No major vessels (180 occurrences)\\n\"\n",
        "                                      \"  1: One major vessel (65 occurrences)\\n\"\n",
        "                                      \"  2: Two major vessels (38 occurrences)\\n\"\n",
        "                                      \"  3: Three major vessels (20 occurrences)\\n\"\n",
        "                                      \"Enter the number of major vessels: \"))\n",
        "            if 0 <= major_vessels <= 3:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter a value between 0 and 3.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a numeric value.\")\n",
        "\n",
        "    # Thallium Stress (normal/fixed_defect/reversible_defect)\n",
        "    # - normal: 3 (168 occurrences)\n",
        "    # - fixed_defect: 6 (18 occurrences)\n",
        "    # - reversible_defect: 7 (117 occurrences)\n",
        "    while True:\n",
        "        try:\n",
        "            thallium_stress = int(input(\"Thallium Stress (3/6/7): \\n\"\n",
        "                                       \"  3: Normal (168 occurrences)\\n\"\n",
        "                                       \"  6: Fixed defect (18 occurrences)\\n\"\n",
        "                                       \"  7: Reversible defect (117 occurrences)\\n\"\n",
        "                                       \"Enter your thallium stress result: \"))\n",
        "            if thallium_stress in [3, 6, 7]:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter 3 for normal, 6 for fixed defect, or 7 for reversible defect.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a numeric value.\")\n",
        "\n",
        "    # Max Heart Rate Binned (1-5)\n",
        "    # - 1: Less than 100 beats per minute (3 occurrences)\n",
        "    # - 2: 100-120 beats per minute (34 occurrences)\n",
        "    # - 3: 120-140 beats per minute (102 occurrences)\n",
        "    # - 4: 140-160 beats per minute (146 occurrences)\n",
        "    # - 5: More than 160 beats per minute (18 occurrences)\n",
        "    while True:\n",
        "        try:\n",
        "            max_heart_rate_binned = int(input(\"Max Heart Rate Binned (1-5): \\n\"\n",
        "                                             \"  1: Less than 100 beats per minute (3 occurrences)\\n\"\n",
        "                                             \"  2: 100-120 beats per minute (34 occurrences)\\n\"\n",
        "                                             \"  3: 120-140 beats per minute (102 occurrences)\\n\"\n",
        "                                             \"  4: 140-160 beats per minute (146 occurrences)\\n\"\n",
        "                                             \"  5: More than 160 beats per minute (18 occurrences)\\n\"\n",
        "                                             \"Enter your max heart rate binned value: \"))\n",
        "            if 1 <= max_heart_rate_binned <= 5:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter a value between 1 and 5.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a numeric value.\")\n",
        "\n",
        "    # Old Peak Binned (1-5)\n",
        "    # - 1: Less than 0.5 mm (135 occurrences)\n",
        "    # - 2: 0.5-1.5 mm (83 occurrences)\n",
        "    # - 3: 1.5-2.5 mm (47 occurrences)\n",
        "    # - 4: 2.5-3.5 mm (25 occurrences)\n",
        "    # - 5: More than 3.5 mm (13 occurrences)\n",
        "    while True:\n",
        "        try:\n",
        "            old_peak_binned = int(input(\"Old Peak Binned (1-5): \\n\"\n",
        "                                       \"  1: Less than 0.5 mm (135 occurrences)\\n\"\n",
        "                                       \"  2: 0.5-1.5 mm (83 occurrences)\\n\"\n",
        "                                       \"  3: 1.5-2.5 mm (47 occurrences)\\n\"\n",
        "                                       \"  4: 2.5-3.5 mm (25 occurrences)\\n\"\n",
        "                                       \"  5: More than 3.5 mm (13 occurrences)\\n\"\n",
        "                                       \"Enter your old peak binned value: \"))\n",
        "            if 1 <= old_peak_binned <= 5:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter a value between 1 and 5.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a numeric value.\")\n",
        "\n",
        "    # Create input data list\n",
        "    input_data = [\n",
        "        gender,\n",
        "        chest_pain_type,\n",
        "        exercise_angina,\n",
        "        exercise_slope,\n",
        "        major_vessels,\n",
        "        thallium_stress,\n",
        "        max_heart_rate_binned,\n",
        "        old_peak_binned\n",
        "    ]\n",
        "\n",
        "    # Scale the input data\n",
        "    input_data = scaler.transform([input_data])\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(input_data)\n",
        "    probability = model.predict_proba(input_data)\n",
        "    print(\"Prediction: \",prediction)\n",
        "\n",
        "    print(f\"Prediction: {'Yes' if prediction == 1 else 'No'}\")\n",
        "    # Probability[0] for 0, [1] for 1\n",
        "    print(f\"Probability: {probability}\")\n",
        "\n",
        "# Run the function to get user input and predict\n",
        "get_user_input_and_predict()\n"
      ],
      "metadata": {
        "id": "9MMAyxXN4G0y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}